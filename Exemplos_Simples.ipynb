{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Exemplos Simples.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMY8+55KZq1XxF0hM8NAfYB",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Andersonsstr/Exemplos-Simples-Machine-Learn-Sklearn-/blob/main/Exemplos_Simples.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FLziuZWBB41u",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "adf7d869-83f2-4dd2-da6a-52604c30507b"
      },
      "source": [
        "#Preparando os dados para utilizar nos testes e dividindo eles para treino e teste\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X = np.array([[-1, -1], [-2, -1], [1, 1], [2, 1], [-4, -3], [-5, -1], [5, 2], [3, 2]])\n",
        "y = np.array([1, 1, 2, 2, 1, 1, 2, 2])\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)\n",
        "print(\"Conjunto Treino X:\", X_train)\n",
        "print(\"Conjunto Teste X:\", X_test)\n",
        "print(\"Conjunto Treino Y:\", y_train)\n",
        "print(\"Conjunto Teste Y:\", y_test)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Conjunto Treino X: [[-2 -1]\n",
            " [ 3  2]\n",
            " [ 2  1]\n",
            " [-1 -1]\n",
            " [-5 -1]\n",
            " [-4 -3]]\n",
            "Conjunto Teste X: [[5 2]\n",
            " [1 1]]\n",
            "Conjunto Treino Y: [1 2 2 1 1 1]\n",
            "Conjunto Teste Y: [2 2]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g49GVcWTBt-V"
      },
      "source": [
        "#Regressão Logística"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oPqSq79k0Izu"
      },
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "lr = LogisticRegression()\n",
        "model = lr.fit(X_train, y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "26lQRS7u14zR",
        "outputId": "34c8050c-1fa4-4957-92c8-1849e6755171"
      },
      "source": [
        "print(\"Dados de teste: \", X_test)\n",
        "print(\"Predictions X Test:\", model.predict(X_test))\n",
        "print(\"Predictions Manual:\", model.predict([[-1, -2], [1,0], [10,20], [-1,-1]]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Dados de teste:  [[5 2]\n",
            " [1 1]]\n",
            "Predictions X Test: [2 2]\n",
            "Predictions Manual: [1 2 2 1]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zq5ZXpHBCgqG"
      },
      "source": [
        "#Gradiente Estocástico Descendente\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dl1jEQdlCewd",
        "outputId": "f49152ff-1882-4954-da38-3c10fc78da7e"
      },
      "source": [
        "from sklearn.linear_model import SGDClassifier\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.pipeline import make_pipeline\n",
        "\n",
        "clf = make_pipeline(StandardScaler(),\n",
        "                    SGDClassifier(max_iter=1000, tol=1e-3))\n",
        "clf.fit(X, y)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(memory=None,\n",
              "         steps=[('standardscaler',\n",
              "                 StandardScaler(copy=True, with_mean=True, with_std=True)),\n",
              "                ('sgdclassifier',\n",
              "                 SGDClassifier(alpha=0.0001, average=False, class_weight=None,\n",
              "                               early_stopping=False, epsilon=0.1, eta0=0.0,\n",
              "                               fit_intercept=True, l1_ratio=0.15,\n",
              "                               learning_rate='optimal', loss='hinge',\n",
              "                               max_iter=1000, n_iter_no_change=5, n_jobs=None,\n",
              "                               penalty='l2', power_t=0.5, random_state=None,\n",
              "                               shuffle=True, tol=0.001, validation_fraction=0.1,\n",
              "                               verbose=0, warm_start=False))],\n",
              "         verbose=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XIHiMAg3C4nV",
        "outputId": "0b848bea-a199-4418-f19b-756a5c865ff0"
      },
      "source": [
        "print(clf.predict([[2, 3], [-1, -2], [1,0], [-1, -3]]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[2 1 2 1]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-_v89LdHCUlt"
      },
      "source": [
        "#Classificador de Árvore Randômica"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AIRqCCh95kB5"
      },
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "rf = RandomForestClassifier()\n",
        "rf_model = rf.fit(X_train, y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vgfuhQ-lDHh5",
        "outputId": "7ff3bcf7-d874-493a-e7f8-e94ee8f55783"
      },
      "source": [
        "\n",
        "print(\"Predictions X Test:\", rf_model.predict(X_test))\n",
        "print(\"Predictions Manual:\", rf_model.predict([[-1, -2], [1,2], [10,20], [-1,-1]]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Predictions X Test: [2 2]\n",
            "Predictions Manual: [1 2 2 1]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rknJwo_aEGJ8"
      },
      "source": [
        "#Pré Processamento"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KaxvIGcGEVyQ"
      },
      "source": [
        "Na maioria dos projetos de aprendizado de máquina do mundo real, os dados que você usa não estarão necessariamente prontos para treinar um modelo. É altamente provável que primeiro você precise executar algumas etapas de pré-processamento e transformação de dados, como manipulação de valores ausentes, transformação de dados categóricos em numéricos ou aplicação de escala de recursos.\n",
        "\n",
        "O Scikit-learn possui métodos integrados para executar essas etapas de pré-processamento. Por exemplo, o SimpleImputer () preenche os valores ausentes usando um método de sua escolha.\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9MHay-_eEfpG"
      },
      "source": [
        "from sklearn.impute import SimpleImputer\n",
        "\n",
        "imputer = SimpleImputer(strategy='mean')\n",
        "X_train_clean = imputer.fit(X_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vyxfmBniF_mX"
      },
      "source": [
        "#Avaliação"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0BIoeSCdGYap"
      },
      "source": [
        "Uma vez que um modelo tenha sido treinado, você precisa medir o quão bom ele é na previsão de novos dados. Esta etapa é conhecida como avaliação do modelo e a métrica que você escolher será determinada pela tarefa que você está tentando resolver. Por exemplo, normalmente em um problema de regressão, você pode escolher RMSE, enquanto para classificação você pode escolher a pontuação F1.\n",
        "\n",
        "Todos os estimadores incluem um método score () que retorna uma métrica padrão que é mais relevante para a tarefa de aprendizado de máquina que executam.\n",
        "\n",
        "Além disso, o Scikit-learn possui um conjunto de funções métricas que fornecem uma avaliação mais detalhada para um modelo. Como exemplo, para tarefas de classificação, a biblioteca possui um relatório de classificação que fornece precisão, recall, pontuação F1 e acurácia geral.\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6rY1Mmd-GNte",
        "outputId": "3d9a1a01-a0cd-4e38-eb73-1f83906d6c5d"
      },
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "rf = RandomForestClassifier()\n",
        "rf_model = rf.fit(X_train, y_train)\n",
        "rf_predictions = rf_model.predict(X_test)\n",
        "print(classification_report(rf_predictions, y_test))"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           2       1.00      1.00      1.00         2\n",
            "\n",
            "    accuracy                           1.00         2\n",
            "   macro avg       1.00      1.00      1.00         2\n",
            "weighted avg       1.00      1.00      1.00         2\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3_1gSPCkv0Qz"
      },
      "source": [
        "#Otimização de Modelo"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D3C5Iqgbve_N"
      },
      "source": [
        "\n",
        "Todos os estimadores na biblioteca Scikit-learn contêm uma variedade de parâmetros, para os quais existem várias opções. Os valores que você escolhe para um determinado algoritmo afetarão o desempenho do modelo final. Por exemplo, com o RandomForestClassifier você pode definir o max_depth da árvore para potencialmente qualquer valor e, dependendo de seus dados e tarefa, diferentes valores para este parâmetro produzirão resultados diferentes.\n",
        "\n",
        "Este processo de tentar diferentes combinações de parâmetros para encontrar a combinação ideal é conhecido como **otimização de hiperparâmetros**.\n",
        "\n",
        "O Scikit-learn fornece duas ferramentas para realizar essa tarefa automaticamente, **GridSearchCV** , que implementa uma técnica conhecida como pesquisa exaustiva em grade, e **RandomizedSearchCV**, que executa a **otimização de parâmetros aleatórios**.\n",
        "\n",
        "O exemplo a seguir usa GridSearchCV para encontrar os parâmetros ideais para o RandomForestClassifier. A saída é mostrada abaixo do código.\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 867
        },
        "id": "PQvK7or5wmeb",
        "outputId": "ea87f163-166a-41b4-9e8d-a49927128b5c"
      },
      "source": [
        "param_grid = { \n",
        "    'n_estimators': [200, 500],\n",
        "    'max_features': ['auto', 'sqrt', 'log2'],\n",
        "    'max_depth' : [4,5,6,7,8],\n",
        "    'criterion' :['gini', 'entropy']\n",
        "}\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "CV = GridSearchCV(rf, param_grid, n_jobs= 1)\n",
        "print(X_train, y_train) \n",
        "print(CV)                 \n",
        "CV.fit(X_train, y_train)  \n",
        "print(CV.best_params_)    \n",
        "print(CV.best_score_)"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[-2 -1]\n",
            " [ 3  2]\n",
            " [ 2  1]\n",
            " [-1 -1]\n",
            " [-5 -1]\n",
            " [-4 -3]] [1 2 2 1 1 1]\n",
            "GridSearchCV(cv=None, error_score=nan,\n",
            "             estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0,\n",
            "                                              class_weight=None,\n",
            "                                              criterion='gini', max_depth=None,\n",
            "                                              max_features='auto',\n",
            "                                              max_leaf_nodes=None,\n",
            "                                              max_samples=None,\n",
            "                                              min_impurity_decrease=0.0,\n",
            "                                              min_impurity_split=None,\n",
            "                                              min_samples_leaf=1,\n",
            "                                              min_samples_split=2,\n",
            "                                              min_weight_fraction_leaf=0.0,\n",
            "                                              n_estimators=100, n_jobs=None,\n",
            "                                              oob_score=False,\n",
            "                                              random_state=None, verbose=0,\n",
            "                                              warm_start=False),\n",
            "             iid='deprecated', n_jobs=1,\n",
            "             param_grid={'criterion': ['gini', 'entropy'],\n",
            "                         'max_depth': [4, 5, 6, 7, 8],\n",
            "                         'max_features': ['auto', 'sqrt', 'log2'],\n",
            "                         'n_estimators': [200, 500]},\n",
            "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
            "             scoring=None, verbose=0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-32-3dbceefcabd8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mCV\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mCV\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mCV\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_params_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mCV\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_score_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    708\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    709\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 710\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    711\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    712\u001b[0m         \u001b[0;31m# For multi-metric evaluation, store the best_index_, best_params_ and\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1149\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1150\u001b[0m         \u001b[0;34m\"\"\"Search all candidates in param_grid\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1151\u001b[0;31m         \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mParameterGrid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1152\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1153\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[0;34m(candidate_params)\u001b[0m\n\u001b[1;32m    687\u001b[0m                                \u001b[0;32mfor\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    688\u001b[0m                                in product(candidate_params,\n\u001b[0;32m--> 689\u001b[0;31m                                           cv.split(X, y, groups)))\n\u001b[0m\u001b[1;32m    690\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    691\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_split.py\u001b[0m in \u001b[0;36msplit\u001b[0;34m(self, X, y, groups)\u001b[0m\n\u001b[1;32m    333\u001b[0m                 .format(self.n_splits, n_samples))\n\u001b[1;32m    334\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 335\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroups\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    336\u001b[0m             \u001b[0;32myield\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    337\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_split.py\u001b[0m in \u001b[0;36msplit\u001b[0;34m(self, X, y, groups)\u001b[0m\n\u001b[1;32m     78\u001b[0m         \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroups\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindexable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroups\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m         \u001b[0mindices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_num_samples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 80\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mtest_index\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iter_test_masks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroups\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     81\u001b[0m             \u001b[0mtrain_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogical_not\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m             \u001b[0mtest_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtest_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_split.py\u001b[0m in \u001b[0;36m_iter_test_masks\u001b[0;34m(self, X, y, groups)\u001b[0m\n\u001b[1;32m    690\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    691\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_iter_test_masks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroups\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 692\u001b[0;31m         \u001b[0mtest_folds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_test_folds\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    693\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_splits\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    694\u001b[0m             \u001b[0;32myield\u001b[0m \u001b[0mtest_folds\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_split.py\u001b[0m in \u001b[0;36m_make_test_folds\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    661\u001b[0m             raise ValueError(\"n_splits=%d cannot be greater than the\"\n\u001b[1;32m    662\u001b[0m                              \u001b[0;34m\" number of members in each class.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 663\u001b[0;31m                              % (self.n_splits))\n\u001b[0m\u001b[1;32m    664\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_splits\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mmin_groups\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    665\u001b[0m             warnings.warn((\"The least populated class in y has only %d\"\n",
            "\u001b[0;31mValueError\u001b[0m: n_splits=5 cannot be greater than the number of members in each class."
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dciG97U2ve6S"
      },
      "source": [
        ""
      ]
    }
  ]
}